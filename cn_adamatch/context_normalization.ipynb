{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8MvR3ZkXYFg"
   },
   "source": [
    "# **Install and Load Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k01fUnNeWe46"
   },
   "outputs": [],
   "source": [
    "# Install tensorflow-addons\n",
    "! pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7yM5cxRY9bD"
   },
   "outputs": [],
   "source": [
    "# Install tensorflow-datasets\n",
    "! pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojYc80fLfBFt"
   },
   "outputs": [],
   "source": [
    "# Install keras-cv for data augmentation\n",
    "! pip install --upgrade keras_cv keras_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3HQDY92YuXF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.datasets import cifar100, cifar10\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy.random import rand\n",
    "from pylab import figure\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, SparseTopKCategoricalAccuracy, Precision, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import keras_cv\n",
    "# Import context normalization layer\n",
    "import os\n",
    "import sys\n",
    "package_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(package_dir)\n",
    "sys.path.append(root_dir)\n",
    "from normalization.layers import ContextNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jcPPz9IbsbH"
   },
   "source": [
    "# **Import MNIST (source domain) and SHVN (target domain)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTnB8eJEdCnD"
   },
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "(\n",
    "    (mnist_x_train, mnist_y_train),\n",
    "    (mnist_x_test, mnist_y_test),\n",
    ") = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Add a channel dimension\n",
    "mnist_x_train = tf.expand_dims(mnist_x_train, -1)\n",
    "mnist_x_test = tf.expand_dims(mnist_x_test, -1)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "mnist_y_train = tf.one_hot(mnist_y_train, 10).numpy()\n",
    "\n",
    "# Load SVHN\n",
    "svhn_train, svhn_test = tfds.load(\n",
    "    \"svhn_cropped\", split=[\"train\", \"test\"], as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc6VSrRadWwp"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "class CFG:\n",
    "    RESIZE_TO = 32\n",
    "    SOURCE_BATCH_SIZE = 64\n",
    "    TARGET_BATCH_SIZE = 3 * SOURCE_BATCH_SIZE  # Reference: Section 3.2\n",
    "    EPOCHS = 100\n",
    "    STEPS_PER_EPOCH = len(mnist_x_train) // SOURCE_BATCH_SIZE\n",
    "    TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "    LEARNING_RATE = 0.03\n",
    "    WEIGHT_DECAY = 0.0005\n",
    "    INIT = \"he_normal\"\n",
    "    DEPTH = 28\n",
    "    WIDTH_MULT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvO_5Lg7f2Tz"
   },
   "source": [
    "# **Data Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edaWuNuegDaj"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "augmenter = keras_cv.layers.RandAugment(value_range=(0, 255), augmentations_per_image=2, magnitude=0.5)\n",
    "\n",
    "def weak_augment(image, source=True):\n",
    "    if image.dtype != tf.float32:\n",
    "        image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # MNIST images are grayscale, this is why we first convert them to\n",
    "    # RGB images.\n",
    "    if source:\n",
    "        image = tf.image.resize_with_pad(image, RESIZE_TO, RESIZE_TO)\n",
    "        image = tf.tile(image, [1, 1, 3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_crop(image, (RESIZE_TO, RESIZE_TO, 3))\n",
    "    return image\n",
    "\n",
    "\n",
    "def strong_augment(image, source=True):\n",
    "    if image.dtype != tf.float32:\n",
    "        image = tf.cast(image, tf.float32)\n",
    "\n",
    "    if source:\n",
    "        image = tf.image.resize_with_pad(image, RESIZE_TO, RESIZE_TO)\n",
    "        image = tf.tile(image, [1, 1, 3])\n",
    "    image = augmenter(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEeWV9uOg38Z"
   },
   "outputs": [],
   "source": [
    "# Make batch\n",
    "def create_individual_ds(ds, aug_func, source=True):\n",
    "    if source:\n",
    "        batch_size = SOURCE_BATCH_SIZE\n",
    "    else:\n",
    "        # During training 3x more target unlabeled samples are shown\n",
    "        # to the model in AdaMatch (Section 3.2 of the paper).\n",
    "        batch_size = TARGET_BATCH_SIZE\n",
    "    ds = ds.shuffle(batch_size * 10, seed=42)\n",
    "\n",
    "    if source:\n",
    "        ds = ds.map(lambda x, y: (aug_func(x), y, [1,0]), num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda x, y: (aug_func(x, False), y, [0,1]), num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "source_ds = tf.data.Dataset.from_tensor_slices((mnist_x_train, mnist_y_train))\n",
    "source_ds_w = create_individual_ds(source_ds, weak_augment)\n",
    "source_ds_s = create_individual_ds(source_ds, strong_augment)\n",
    "final_source_ds = tf.data.Dataset.zip((source_ds_w, source_ds_s))\n",
    "\n",
    "target_ds_w = create_individual_ds(svhn_train, weak_augment, source=False)\n",
    "target_ds_s = create_individual_ds(svhn_train, strong_augment, source=False)\n",
    "final_target_ds = tf.data.Dataset.zip((target_ds_w, target_ds_s))\n",
    "\n",
    "\n",
    "total_ds = tf.data.Dataset.zip((final_source_ds, final_target_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCn36hZHhV7P"
   },
   "source": [
    "# **Define Loss for Source and Target domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HhANCUIhbkC"
   },
   "outputs": [],
   "source": [
    "# Compute source loss\n",
    "def compute_loss_source(source_labels, logits_source_w, logits_source_s):\n",
    "    loss_func = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    # First compute the losses between original source labels and\n",
    "    # predictions made on the weakly and strongly augmented versions\n",
    "    # of the same images.\n",
    "    w_loss = loss_func(source_labels, logits_source_w)\n",
    "    s_loss = loss_func(source_labels, logits_source_s)\n",
    "    return w_loss + s_loss\n",
    "\n",
    "\n",
    "# Computer Target Loss\n",
    "def compute_loss_target(target_pseudo_labels_w, logits_target_s, mask):\n",
    "    loss_func = keras.losses.CategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
    "    target_pseudo_labels_w = tf.stop_gradient(target_pseudo_labels_w)\n",
    "    # For calculating loss for the target samples, we treat the pseudo labels\n",
    "    # as the ground-truth. These are not considered during backpropagation\n",
    "    # which is a standard Semi-supervised Learning (SSL) practice.\n",
    "    target_loss = loss_func(target_pseudo_labels_w, logits_target_s)\n",
    "\n",
    "    mask = tf.cast(mask, target_loss.dtype)\n",
    "    target_loss *= mask\n",
    "    return tf.reduce_mean(target_loss, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfVXQJBDj__v"
   },
   "source": [
    "# **Build AdaMatch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1xMkAA8kHra"
   },
   "outputs": [],
   "source": [
    "class AdaMatch(keras.Model):\n",
    "    def __init__(self, model, total_steps, tau=0.9):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tau = tau  # Denotes the confidence threshold\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.total_steps = total_steps\n",
    "        self.current_step = tf.Variable(0, dtype=\"int64\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "    # This is a warmup schedule to update the weight of the\n",
    "    # loss contributed by the target unlabeled samples. More\n",
    "    # on this in the text.\n",
    "    def compute_mu(self):\n",
    "        pi = tf.constant(np.pi, dtype=\"float32\")\n",
    "        step = tf.cast(self.current_step, dtype=\"float32\")\n",
    "        return 0.5 - tf.cos(tf.math.minimum(pi, (2 * pi * step) / self.total_steps)) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        ## Unpack and organize the data\n",
    "        source_ds, target_ds = data\n",
    "        (source_w, source_labels, source_context_w), (source_s, _, source_context_s) = source_ds\n",
    "        ((target_w, _, target_context_w), (target_s, _, target_context_s),) = target_ds  # Notice that we are NOT using any labels here.\n",
    "\n",
    "        combined_images = tf.concat([source_w, source_s, target_w, target_s], 0)\n",
    "        combined_source = tf.concat([source_w, source_s], 0)\n",
    "\n",
    "        combined_context = tf.concat([source_context_w, source_context_s, target_context_w, target_context_s], 0)\n",
    "        combined_source_context = tf.concat([source_context_w, source_context_s], 0)\n",
    "\n",
    "        total_source = tf.shape(combined_source)[0]\n",
    "        total_target = tf.shape(tf.concat([target_w, target_s], 0))[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Forward passes ##\n",
    "            combined_logits = self.model([combined_images, combined_context], training=True)\n",
    "            z_d_prime_source = self.model(\n",
    "                [combined_source, combined_source_context], training=False\n",
    "              )  # No BatchNorm update.\n",
    "            z_prime_source = combined_logits[:total_source]\n",
    "\n",
    "            ## 1. Random logit interpolation for the source images ##\n",
    "            lambd = tf.random.uniform((total_source, 10), 0, 1) # 10 output dim (number of class of mnist)\n",
    "\n",
    "            final_source_logits = (lambd * z_prime_source) + (\n",
    "                (1 - lambd) * z_d_prime_source\n",
    "            )\n",
    "\n",
    "            ## 2. Distribution alignment (only consider weakly augmented images) ##\n",
    "            # Compute softmax for logits of the WEAKLY augmented SOURCE images.\n",
    "            y_hat_source_w = tf.nn.softmax(final_source_logits[: tf.shape(source_w)[0]])\n",
    "\n",
    "            # Extract logits for the WEAKLY augmented TARGET images and compute softmax.\n",
    "            logits_target = combined_logits[total_source:]\n",
    "            logits_target_w = logits_target[: tf.shape(target_w)[0]]\n",
    "            y_hat_target_w = tf.nn.softmax(logits_target_w)\n",
    "\n",
    "            # Align the target label distribution to that of the source.\n",
    "            expectation_ratio = tf.reduce_mean(y_hat_source_w) / tf.reduce_mean(\n",
    "                y_hat_target_w\n",
    "            )\n",
    "            y_tilde_target_w = tf.math.l2_normalize(\n",
    "                y_hat_target_w * expectation_ratio, 1\n",
    "            )\n",
    "\n",
    "            ## 3. Relative confidence thresholding ##\n",
    "            row_wise_max = tf.reduce_max(y_hat_source_w, axis=-1)\n",
    "            final_sum = tf.reduce_mean(row_wise_max, 0)\n",
    "            c_tau = self.tau * final_sum\n",
    "            mask = tf.reduce_max(y_tilde_target_w, axis=-1) >= c_tau\n",
    "\n",
    "            ## Compute losses (pay attention to the indexing) ##\n",
    "            source_loss = compute_loss_source(\n",
    "                source_labels,\n",
    "                final_source_logits[: tf.shape(source_w)[0]],\n",
    "                final_source_logits[tf.shape(source_w)[0] :],\n",
    "            )\n",
    "            target_loss = compute_loss_target(\n",
    "                y_tilde_target_w, logits_target[tf.shape(target_w)[0] :], mask\n",
    "            )\n",
    "\n",
    "            t = self.compute_mu()  # Compute weight for the target loss\n",
    "            total_loss = source_loss + (t * target_loss)\n",
    "            self.current_step.assign_add(\n",
    "                1\n",
    "            )  # Update current training step for the scheduler\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igrNjPDtkX2i"
   },
   "outputs": [],
   "source": [
    "def wide_basic(x, n_input_plane, n_output_plane, stride):\n",
    "    conv_params = [[3, 3, stride, \"same\"], [3, 3, (1, 1), \"same\"]]\n",
    "    n_bottleneck_plane = n_output_plane\n",
    "    # Residual block\n",
    "    for i, v in enumerate(conv_params):\n",
    "        if i == 0:\n",
    "            if n_input_plane != n_output_plane:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "                x = layers.Activation(\"relu\")(x)\n",
    "                convs = x\n",
    "            else:\n",
    "                convs = layers.BatchNormalization()(x)\n",
    "                convs = layers.Activation(\"relu\")(convs)\n",
    "            convs = layers.Conv2D(\n",
    "                n_bottleneck_plane,\n",
    "                (v[0], v[1]),\n",
    "                strides=v[2],\n",
    "                padding=v[3],\n",
    "                kernel_initializer=CFG.INIT,\n",
    "                kernel_regularizer=regularizers.l2(CFG.WEIGHT_DECAY),\n",
    "                use_bias=False,\n",
    "            )(convs)\n",
    "        else:\n",
    "            convs = layers.BatchNormalization()(convs)\n",
    "            convs = layers.Activation(\"relu\")(convs)\n",
    "            convs = layers.Conv2D(\n",
    "                n_bottleneck_plane,\n",
    "                (v[0], v[1]),\n",
    "                strides=v[2],\n",
    "                padding=v[3],\n",
    "                kernel_initializer=CFG.INIT,\n",
    "                kernel_regularizer=regularizers.l2(CFG.WEIGHT_DECAY),\n",
    "                use_bias=False,\n",
    "            )(convs)\n",
    "\n",
    "    # Shortcut connection: identity function or 1x1\n",
    "    # convolutional\n",
    "    #  (depends on difference between input & output shape - this\n",
    "    #   corresponds to whether we are using the first block in\n",
    "    #   each\n",
    "    #   group; see `block_series()`).\n",
    "    if n_input_plane != n_output_plane:\n",
    "        shortcut = layers.Conv2D(\n",
    "            n_output_plane,\n",
    "            (1, 1),\n",
    "            strides=stride,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=CFG.INIT,\n",
    "            kernel_regularizer=regularizers.l2(CFG.WEIGHT_DECAY),\n",
    "            use_bias=False,\n",
    "        )(x)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    return layers.Add()([convs, shortcut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D49Dutgckd7d"
   },
   "outputs": [],
   "source": [
    "# Stacking residual units on the same stage\n",
    "def block_series(x, n_input_plane, n_output_plane, count, stride):\n",
    "    x = wide_basic(x, n_input_plane, n_output_plane, stride)\n",
    "    for i in range(2, int(count + 1)):\n",
    "        x = wide_basic(x, n_output_plane, n_output_plane, stride=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwIjV2c2kuYP"
   },
   "outputs": [],
   "source": [
    "def get_network(image_size=32, num_classes=10, num_channels=3):\n",
    "    n = (CFG.DEPTH - 4) / 6\n",
    "    n_stages = [16, 16 * CFG.WIDTH_MULT, 32 * CFG.WIDTH_MULT, 64 * CFG.WIDTH_MULT]\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(image_size, image_size, 3))\n",
    "    context_id = tf.keras.Input(shape=(2,))\n",
    "    # Normalize inputs with context normalization\n",
    "    x = normalized_inputs = ContextNormalization()([inputs, context_id])\n",
    "\n",
    "    conv1 = layers.Conv2D(\n",
    "        n_stages[0],\n",
    "        (3, 3),\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=CFG.INIT,\n",
    "        kernel_regularizer=regularizers.l2(CFG.WEIGHT_DECAY),\n",
    "        use_bias=False,\n",
    "    )(x)\n",
    "\n",
    "    ## Add wide residual blocks ##\n",
    "\n",
    "    conv2 = block_series(\n",
    "        conv1,\n",
    "        n_input_plane=n_stages[0],\n",
    "        n_output_plane=n_stages[1],\n",
    "        count=n,\n",
    "        stride=(1, 1),\n",
    "    )  # Stage 1\n",
    "\n",
    "    conv3 = block_series(\n",
    "        conv2,\n",
    "        n_input_plane=n_stages[1],\n",
    "        n_output_plane=n_stages[2],\n",
    "        count=n,\n",
    "        stride=(2, 2),\n",
    "    )  # Stage 2\n",
    "\n",
    "    conv4 = block_series(\n",
    "        conv3,\n",
    "        n_input_plane=n_stages[2],\n",
    "        n_output_plane=n_stages[3],\n",
    "        count=n,\n",
    "        stride=(2, 2),\n",
    "    )  # Stage 3\n",
    "\n",
    "    batch_norm = layers.BatchNormalization()(conv4)\n",
    "    relu = layers.Activation(\"relu\")(batch_norm)\n",
    "\n",
    "    # Classifier\n",
    "    trunk_outputs = layers.GlobalAveragePooling2D()(relu)\n",
    "    outputs = layers.Dense(\n",
    "        num_classes, kernel_regularizer=regularizers.l2(CFG.WEIGHT_DECAY)\n",
    "    )(trunk_outputs)\n",
    "\n",
    "    return keras.Model([inputs, context_id], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXYSigtslT72"
   },
   "source": [
    "# **Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anaAQDBglYfC"
   },
   "outputs": [],
   "source": [
    "wrn_model = get_network()\n",
    "reduce_lr = tf.keras.optimizers.schedules.CosineDecay(CFG.LEARNING_RATE, CFG.TOTAL_STEPS, 0.25)\n",
    "optimizer = keras.optimizers.Adam(reduce_lr)\n",
    "model = AdaMatch(model=wrn_model, total_steps=CFG.TOTAL_STEPS)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6xijtS5ltqM"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"model.ckpt\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  checkpoint_filepath,\n",
    "  monitor=\"loss\",\n",
    "  save_best_only=True,\n",
    "  save_weights_only=True\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    history = model.fit(total_ds, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpm3fEWXm-FC"
   },
   "outputs": [],
   "source": [
    "# Save loss\n",
    "write_list(history.history['loss'], 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3mGurcBnUw0"
   },
   "source": [
    "# **Evaluate trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3jS1TCqrf7I"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "optimizer = Adam(learning_rate=reduce_lr)\n",
    "model = AdaMatch(model=wrn_model, total_steps=CFG.TOTAL_STEPS)\n",
    "model.compile(optimizer=optimizer)\n",
    "model.load_weights(\"model.ckpt\")\n",
    "adamatch_trained_model = model.model\n",
    "adamatch_trained_model.compile(metrics=keras.metrics.SparseCategoricalAccuracy())\n",
    "context_source_id = 0\n",
    "context_target_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8kSc-XznK-D"
   },
   "outputs": [],
   "source": [
    "# TARGET\n",
    "print(\"############################ TARGET (SVHN) ################\")\n",
    "def extract_inputs(item1, item2):\n",
    "    return (item1, item2)\n",
    "\n",
    "svhn_mapping = svhn_test.map(lambda x, y: ((x, [1, 0]), y), num_parallel_calls=AUTO)\n",
    "svhn_mapping = svhn_mapping.batch(TARGET_BATCH_SIZE).prefetch(AUTO)\n",
    "_, accuracy = adamatch_trained_model.evaluate(svhn_mapping)\n",
    "svhn_mapping = svhn_test.map(lambda x, y: ((x, [1, 0]), y), num_parallel_calls=AUTO)\n",
    "svhn_mapping = svhn_mapping.map(lambda x, y: (x, [1, 0]))\n",
    "svhn_mapping = svhn_mapping.map(extract_inputs)\n",
    "svhn_mapping = svhn_mapping.batch(TARGET_BATCH_SIZE).prefetch(AUTO)\n",
    "predictions_svhn = adamatch_trained_model.predict(svhn_mapping)\n",
    "svhn_labels = np.array([y.numpy() for (_, y) in svhn_test])\n",
    "precision_svhn, recall_svhn, f1_score_svhn, _ = precision_recall_fscore_support(svhn_labels, np.argmax(predictions_svhn, axis=-1), average='weighted')\n",
    "\n",
    "print(f\"Accuracy on target test set: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision on SVHN using SVHN context: {precision_svhn * 100:.2f}%\")\n",
    "print(f\"Recall on SVHN using SVHN context: {recall_svhn * 100:.2f}%\")\n",
    "print(f\"F1-score on SVHN using SVHN context: {f1_score_svhn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1BGj08gqxZh"
   },
   "outputs": [],
   "source": [
    "# SOURCE\n",
    "print(\"############################### SOURCE (MNIST) #############################\")\n",
    "# Utility function for preprocessing the source test set.\n",
    "def prepare_test_ds_source(image_context, label):\n",
    "    image = image_context[0]\n",
    "    context = image_context[1]\n",
    "    image = tf.image.resize_with_pad(image, CFG.RESIZE_TO, CFG.RESIZE_TO)\n",
    "    image = tf.tile(image, [1, 1, 3])\n",
    "    return (image, context), label\n",
    "\n",
    "def prepare_test_ds(image, context):\n",
    "    image = tf.image.resize_with_pad(image, CFG.RESIZE_TO, CFG.RESIZE_TO)\n",
    "    image = tf.tile(image, [1, 1, 3])\n",
    "    return (image, context)\n",
    "\n",
    "def prepare_source_data(x, context):\n",
    "    return (x, context)\n",
    "\n",
    "def get_image_and_context(image, context):\n",
    "    return (image, context), context\n",
    "\n",
    "context = np.repeat([[1,0]], mnist_x_test.shape[0], axis=0)\n",
    "context = tf.convert_to_tensor(context, dtype=tf.float64)\n",
    "\n",
    "source_test_ds = tf.data.Dataset.from_tensor_slices(((mnist_x_test, context), mnist_y_test))\n",
    "source_test_ds = (\n",
    "    source_test_ds.map(prepare_test_ds_source, num_parallel_calls=AUTO)\n",
    "    .batch(TARGET_BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "_, accuracy = adamatch_trained_model.evaluate(source_test_ds)\n",
    "\n",
    "context_source = np.repeat([[1, 0]], mnist_x_test.shape[0], axis=0)\n",
    "context_source = tf.convert_to_tensor(context_source, dtype=tf.float64)\n",
    "source_test_ds = tf.data.Dataset.from_tensor_slices((mnist_x_test, context_source))\n",
    "\n",
    "source_mapping = source_test_ds.map(prepare_source_data, num_parallel_calls=AUTO)\n",
    "source_mapping = source_mapping.map(prepare_test_ds)\n",
    "\n",
    "x = source_mapping.map(get_image_and_context)\n",
    "x = x.batch(TARGET_BATCH_SIZE).prefetch(AUTO)\n",
    "predictions_source = adamatch_trained_model.predict(x)\n",
    "precision_source, recall_source, f1_score_source, _ = precision_recall_fscore_support(mnist_y_test, np.argmax(predictions_source, axis=-1), average='weighted')\n",
    "\n",
    "print(f\"Accuracy on source test set: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision on source test set using source context: {precision_source * 100:.2f}%\")\n",
    "print(f\"Recall on source test set using source context: {recall_source * 100:.2f}%\")\n",
    "print(f\"F1-score on source test set using source context: {f1_score_source * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
